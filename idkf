{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542bd1af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T09:14:41.524135Z",
     "iopub.status.busy": "2024-07-31T09:14:41.523777Z",
     "iopub.status.idle": "2024-07-31T09:14:55.283043Z",
     "shell.execute_reply": "2024-07-31T09:14:55.281883Z"
    },
    "executionInfo": {
     "elapsed": 8129,
     "status": "ok",
     "timestamp": 1721367100568,
     "user": {
      "displayName": "Kishan Adhikary",
      "userId": "06010834230959638485"
     },
     "user_tz": -345
    },
    "id": "hdTRX7E9GfsF",
    "outputId": "a0fe35a5-df22-4dd5-9776-cff750c8a761",
    "papermill": {
     "duration": 13.766853,
     "end_time": "2024-07-31T09:14:55.285128",
     "exception": false,
     "start_time": "2024-07-31T09:14:41.518275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/handwriting-v3\n",
      "Collecting gdown\r\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\r\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.7.4)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\r\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\r\n",
      "Installing collected packages: gdown\r\n",
      "Successfully installed gdown-5.2.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/input/handwriting-v3\n",
    "%pip install --upgrade --no-cache-dir gdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df542862",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T09:14:55.294782Z",
     "iopub.status.busy": "2024-07-31T09:14:55.294455Z",
     "iopub.status.idle": "2024-07-31T09:14:56.291029Z",
     "shell.execute_reply": "2024-07-31T09:14:56.289752Z"
    },
    "papermill": {
     "duration": 1.004049,
     "end_time": "2024-07-31T09:14:56.293471",
     "exception": false,
     "start_time": "2024-07-31T09:14:55.289422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbfbf8f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T09:14:56.303243Z",
     "iopub.status.busy": "2024-07-31T09:14:56.302935Z",
     "iopub.status.idle": "2024-07-31T09:14:57.345483Z",
     "shell.execute_reply": "2024-07-31T09:14:57.344334Z"
    },
    "papermill": {
     "duration": 1.05047,
     "end_time": "2024-07-31T09:14:57.348227",
     "exception": false,
     "start_time": "2024-07-31T09:14:56.297757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mHandwriting-Transformers\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb1fcc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T09:14:57.359331Z",
     "iopub.status.busy": "2024-07-31T09:14:57.358280Z",
     "iopub.status.idle": "2024-07-31T09:14:57.366080Z",
     "shell.execute_reply": "2024-07-31T09:14:57.365123Z"
    },
    "papermill": {
     "duration": 0.015284,
     "end_time": "2024-07-31T09:14:57.368112",
     "exception": false,
     "start_time": "2024-07-31T09:14:57.352828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/handwriting-v3/Handwriting-Transformers\n"
     ]
    }
   ],
   "source": [
    "%cd Handwriting-Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b31221ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T09:14:57.377558Z",
     "iopub.status.busy": "2024-07-31T09:14:57.377284Z",
     "iopub.status.idle": "2024-07-31T09:14:58.413184Z",
     "shell.execute_reply": "2024-07-31T09:14:58.412280Z"
    },
    "papermill": {
     "duration": 1.043396,
     "end_time": "2024-07-31T09:14:58.415693",
     "exception": false,
     "start_time": "2024-07-31T09:14:57.372297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mFigures\u001b[0m/    README.md   demo_custom_handwriting.ipynb  params.py  \u001b[01;34mutil\u001b[0m/\r\n",
      "INSTALL.md  \u001b[01;34mdata\u001b[0m/       \u001b[01;34mmodels\u001b[0m/                        \u001b[01;34mresults\u001b[0m/\r\n",
      "LICENSE     demo.ipynb  mytext.txt                     train.py\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc03f73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T09:14:58.426172Z",
     "iopub.status.busy": "2024-07-31T09:14:58.425879Z",
     "iopub.status.idle": "2024-07-31T09:14:59.416632Z",
     "shell.execute_reply": "2024-07-31T09:14:59.415615Z"
    },
    "papermill": {
     "duration": 0.998819,
     "end_time": "2024-07-31T09:14:59.419238",
     "exception": false,
     "start_time": "2024-07-31T09:14:58.420419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mFigures\u001b[0m/    README.md   demo_custom_handwriting.ipynb  params.py  \u001b[01;34mutil\u001b[0m/\r\n",
      "INSTALL.md  \u001b[01;34mdata\u001b[0m/       \u001b[01;34mmodels\u001b[0m/                        \u001b[01;34mresults\u001b[0m/\r\n",
      "LICENSE     demo.ipynb  mytext.txt                     train.py\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f8cf6f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T09:14:59.430014Z",
     "iopub.status.busy": "2024-07-31T09:14:59.429666Z",
     "iopub.status.idle": "2024-07-31T09:15:01.703514Z",
     "shell.execute_reply": "2024-07-31T09:15:01.702533Z"
    },
    "papermill": {
     "duration": 2.282008,
     "end_time": "2024-07-31T09:15:01.705890",
     "exception": false,
     "start_time": "2024-07-31T09:14:59.423882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path /kaggle/input/handwriting-v3/Handwriting-Transformers/wandb/ wasn't writable, using system temp directory\r\n",
      "W&B online. Running your script from this directory will now sync to the cloud.\r\n"
     ]
    }
   ],
   "source": [
    "!wandb online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1f9c607",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T09:15:01.717011Z",
     "iopub.status.busy": "2024-07-31T09:15:01.716221Z",
     "iopub.status.idle": "2024-07-31T09:15:14.410946Z",
     "shell.execute_reply": "2024-07-31T09:15:14.409719Z"
    },
    "papermill": {
     "duration": 12.703377,
     "end_time": "2024-07-31T09:15:14.413838",
     "exception": false,
     "start_time": "2024-07-31T09:15:01.710461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.17.4)\r\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\r\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.8.0)\r\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8bab5a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T09:15:14.426717Z",
     "iopub.status.busy": "2024-07-31T09:15:14.426376Z",
     "iopub.status.idle": "2024-07-31T09:29:37.166703Z",
     "shell.execute_reply": "2024-07-31T09:29:37.165583Z"
    },
    "papermill": {
     "duration": 862.749452,
     "end_time": "2024-07-31T09:29:37.169176",
     "exception": false,
     "start_time": "2024-07-31T09:15:14.419724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the main function...\r\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: write).\r\n",
      "Your token has been saved to /root/.cache/huggingface/token\r\n",
      "Login successful\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path /kaggle/input/handwriting-v3/Handwriting-Transformers/wandb/ wasn't writable, using system temp directory.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path /kaggle/input/handwriting-v3/Handwriting-Transformers/wandb/ wasn't writable, using system temp directory\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path /kaggle/input/handwriting-v3/Handwriting-Transformers/wandb/ wasn't writable, using system temp directory\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madarshghimire10\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.5 is available!  To upgrade, please run:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.4\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/tmp/wandb/run-20240731_091523-4hdlo8ig\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCOMBINED_DATA_TRAINING\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/adarshghimire10/hwt-final\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/adarshghimire10/hwt-final/runs/4hdlo8ig\u001b[0m\r\n",
      "Logged into W&B and Hugging Face\r\n",
      "Creating or accessing the Hugging Face repository\r\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\r\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\r\n",
      "  warnings.warn(warning_message, FutureWarning)\r\n",
      "Cloning https://huggingface.co/Adarsh203/HWT_model_save into local empty directory.\r\n",
      "Download file COMBINED_DATA_TRAINING/model_epoch_new.pth: 100%|‚ñâ| 538M/540M [00:\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:   0%| | 1.00k/540M [00:00\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:   0%| | 2.44M/540M [00:01\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:   2%| | 12.0M/540M [00:02\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:   4%| | 21.6M/540M [00:03\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:   6%| | 31.3M/540M [00:04\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:   7%| | 36.3M/540M [00:05\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:   7%| | 37.1M/540M [00:06\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:   8%| | 42.0M/540M [00:07\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  10%| | 51.6M/540M [00:08\u001b[A\r\n",
      "Download file COMBINED_DATA_TRAINING/model_epoch_new.pth: 100%|‚ñà| 540M/540M [01:\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  13%|‚ñè| 70.6M/540M [00:10\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  15%|‚ñè| 79.8M/540M [00:11\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  16%|‚ñè| 88.9M/540M [00:12\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  18%|‚ñè| 98.3M/540M [00:13\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  20%|‚ñè| 108M/540M [00:14<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  22%|‚ñè| 117M/540M [00:15<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  23%|‚ñè| 126M/540M [00:16<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  25%|‚ñé| 136M/540M [00:17<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  27%|‚ñé| 145M/540M [00:18<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  29%|‚ñé| 155M/540M [00:19<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  30%|‚ñé| 165M/540M [00:20<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  32%|‚ñé| 175M/540M [00:21<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  34%|‚ñé| 184M/540M [00:22<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  36%|‚ñé| 194M/540M [00:23<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  38%|‚ñç| 204M/540M [00:24<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  40%|‚ñç| 214M/540M [00:25<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  41%|‚ñç| 224M/540M [00:26<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  43%|‚ñç| 233M/540M [00:27<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  45%|‚ñç| 243M/540M [00:28<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  47%|‚ñç| 253M/540M [00:29<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  48%|‚ñç| 262M/540M [00:30<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  50%|‚ñå| 272M/540M [00:31<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  52%|‚ñå| 281M/540M [00:32<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  54%|‚ñå| 291M/540M [00:33<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  56%|‚ñå| 301M/540M [00:34<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  56%|‚ñå| 305M/540M [00:35<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  58%|‚ñå| 311M/540M [00:36<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  59%|‚ñå| 321M/540M [00:37<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  61%|‚ñå| 331M/540M [00:38<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  63%|‚ñã| 342M/540M [00:39<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  65%|‚ñã| 352M/540M [00:40<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  67%|‚ñã| 362M/540M [00:41<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  69%|‚ñã| 372M/540M [00:42<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  71%|‚ñã| 381M/540M [00:43<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  72%|‚ñã| 391M/540M [00:44<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  74%|‚ñã| 401M/540M [00:45<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  76%|‚ñä| 410M/540M [00:46<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  78%|‚ñä| 420M/540M [00:47<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  80%|‚ñä| 430M/540M [00:48<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  81%|‚ñä| 439M/540M [00:49<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  83%|‚ñä| 449M/540M [00:50<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  85%|‚ñä| 459M/540M [00:51<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  87%|‚ñä| 468M/540M [00:52<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  88%|‚ñâ| 478M/540M [00:53<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  90%|‚ñâ| 487M/540M [00:54<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  92%|‚ñâ| 495M/540M [00:55<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  93%|‚ñâ| 504M/540M [00:56<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  95%|‚ñâ| 514M/540M [00:57<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth:  97%|‚ñâ| 523M/540M [00:58<\u001b[A\r\n",
      "Download file COMBINED_DATA_TRAINING/model_epoch_new.pth: 100%|‚ñà| 540M/540M [02:\r\n",
      "\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth: 100%|‚ñà| 540M/540M [01:00<\u001b[A\r\n",
      "Clean file COMBINED_DATA_TRAINING/model_epoch_new.pth: 100%|‚ñà| 540M/540M [01:00<\r\n",
      "Initializing project\r\n",
      "Creating data loader for training dataset\r\n",
      "Creating data loader for validation dataset\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\r\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:00<00:00, 148MB/s]\r\n",
      "initialize network with N02\r\n",
      "initialize network with N02\r\n",
      "initialize network with N02\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\r\n",
      "  warnings.warn(msg)\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\r\n",
      "  warnings.warn(\r\n",
      "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\r\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91.2M/91.2M [00:00<00:00, 241MB/s]\r\n",
      "Model initialized\r\n",
      "/kaggle/working/saved_models/COMBINED_DATA_TRAINING : Model loaded Successfully\r\n",
      "Starting epoch 0/100000\r\n",
      "Iteration 1 in epoch 0\r\n",
      "Iteration 2 in epoch 0\r\n",
      "Iteration 3 in epoch 0\r\n",
      "Iteration 4 in epoch 0\r\n",
      "Iteration 5 in epoch 0\r\n",
      "Iteration 6 in epoch 0\r\n",
      "Iteration 7 in epoch 0\r\n",
      "Iteration 8 in epoch 0\r\n",
      "Iteration 9 in epoch 0\r\n",
      "Iteration 10 in epoch 0\r\n",
      "Iteration 11 in epoch 0\r\n",
      "Iteration 12 in epoch 0\r\n",
      "Iteration 13 in epoch 0\r\n",
      "Iteration 14 in epoch 0\r\n",
      "Iteration 15 in epoch 0\r\n",
      "Iteration 16 in epoch 0\r\n",
      "Iteration 17 in epoch 0\r\n",
      "Iteration 18 in epoch 0\r\n",
      "Iteration 19 in epoch 0\r\n",
      "Iteration 20 in epoch 0\r\n",
      "Iteration 21 in epoch 0\r\n",
      "Iteration 22 in epoch 0\r\n",
      "Iteration 23 in epoch 0\r\n",
      "Iteration 24 in epoch 0\r\n",
      "Iteration 25 in epoch 0\r\n",
      "Iteration 26 in epoch 0\r\n",
      "Iteration 27 in epoch 0\r\n",
      "Iteration 28 in epoch 0\r\n",
      "Iteration 29 in epoch 0\r\n",
      "Iteration 30 in epoch 0\r\n",
      "Iteration 31 in epoch 0\r\n",
      "Iteration 32 in epoch 0\r\n",
      "Iteration 33 in epoch 0\r\n",
      "Iteration 34 in epoch 0\r\n",
      "Iteration 35 in epoch 0\r\n",
      "Iteration 36 in epoch 0\r\n",
      "Iteration 37 in epoch 0\r\n",
      "Iteration 38 in epoch 0\r\n",
      "Iteration 39 in epoch 0\r\n",
      "Iteration 40 in epoch 0\r\n",
      "Iteration 41 in epoch 0\r\n",
      "Iteration 42 in epoch 0\r\n",
      "Iteration 43 in epoch 0\r\n",
      "Iteration 44 in epoch 0\r\n",
      "Iteration 45 in epoch 0\r\n",
      "Iteration 46 in epoch 0\r\n",
      "Iteration 47 in epoch 0\r\n",
      "Iteration 48 in epoch 0\r\n",
      "Iteration 49 in epoch 0\r\n",
      "Iteration 50 in epoch 0\r\n",
      "Iteration 51 in epoch 0\r\n",
      "Iteration 52 in epoch 0\r\n",
      "Iteration 53 in epoch 0\r\n",
      "Iteration 54 in epoch 0\r\n",
      "Iteration 55 in epoch 0\r\n",
      "Iteration 56 in epoch 0\r\n",
      "Iteration 57 in epoch 0\r\n",
      "Iteration 58 in epoch 0\r\n",
      "Iteration 59 in epoch 0\r\n",
      "Iteration 60 in epoch 0\r\n",
      "Iteration 61 in epoch 0\r\n",
      "Iteration 62 in epoch 0\r\n",
      "Iteration 63 in epoch 0\r\n",
      "Iteration 64 in epoch 0\r\n",
      "Iteration 65 in epoch 0\r\n",
      "Iteration 66 in epoch 0\r\n",
      "Iteration 67 in epoch 0\r\n",
      "Iteration 68 in epoch 0\r\n",
      "Iteration 69 in epoch 0\r\n",
      "Iteration 70 in epoch 0\r\n",
      "Iteration 71 in epoch 0\r\n",
      "Iteration 72 in epoch 0\r\n",
      "Iteration 73 in epoch 0\r\n",
      "Iteration 74 in epoch 0\r\n",
      "Iteration 75 in epoch 0\r\n",
      "Iteration 76 in epoch 0\r\n",
      "Iteration 77 in epoch 0\r\n",
      "Iteration 78 in epoch 0\r\n",
      "Iteration 79 in epoch 0\r\n",
      "Iteration 80 in epoch 0\r\n",
      "Epoch 1 completed in 229.47332644462585 seconds\r\n",
      "{'EPOCH': 0, 'TIME': 229.47332644462585, 'LOSSES': {'G': tensor(1.1641, device='cuda:0', grad_fn=<SubBackward0>), 'D': tensor(0., device='cuda:0', grad_fn=<AddBackward0>), 'Dfake': tensor(0., device='cuda:0', grad_fn=<DivBackward0>), 'Dreal': tensor(0., device='cuda:0', grad_fn=<DivBackward0>), 'OCR_fake': tensor(0.2388, device='cuda:0', grad_fn=<MulBackward0>), 'OCR_real': tensor(4.4487, device='cuda:0', grad_fn=<MeanBackward0>), 'w_fake': tensor(3.1516, device='cuda:0', grad_fn=<MulBackward0>), 'w_real': tensor(4.7200, device='cuda:0', grad_fn=<MeanBackward0>), 'cycle1': 0, 'cycle2': 0, 'lda1': 0, 'lda2': 0, 'KLD': 0}}\r\n",
      "Model at epoch 0 saved\r\n",
      "Upload file COMBINED_DATA_TRAINING/model_epoch_new.pth:  96%|‚ñâ| 519M/540M [00:13To https://huggingface.co/Adarsh203/HWT_model_save\r\n",
      "   92752c6..a1e2570  main -> main\r\n",
      "\r\n",
      "Upload file COMBINED_DATA_TRAINING/model_epoch_new.pth: 100%|‚ñà| 540M/540M [00:14\r\n",
      "Model at epoch 0 pushed to Hugging Face\r\n",
      "Starting epoch 1/100000\r\n",
      "Iteration 1 in epoch 1\r\n",
      "Iteration 2 in epoch 1\r\n",
      "Iteration 3 in epoch 1\r\n",
      "Iteration 4 in epoch 1\r\n",
      "Iteration 5 in epoch 1\r\n",
      "Iteration 6 in epoch 1\r\n",
      "Iteration 7 in epoch 1\r\n",
      "Iteration 8 in epoch 1\r\n",
      "Iteration 9 in epoch 1\r\n",
      "Iteration 10 in epoch 1\r\n",
      "Iteration 11 in epoch 1\r\n",
      "Iteration 12 in epoch 1\r\n",
      "Iteration 13 in epoch 1\r\n",
      "Iteration 14 in epoch 1\r\n",
      "Iteration 15 in epoch 1\r\n",
      "Iteration 16 in epoch 1\r\n",
      "Iteration 17 in epoch 1\r\n",
      "Iteration 18 in epoch 1\r\n",
      "Iteration 19 in epoch 1\r\n",
      "Iteration 20 in epoch 1\r\n",
      "Iteration 21 in epoch 1\r\n",
      "Iteration 22 in epoch 1\r\n",
      "Iteration 23 in epoch 1\r\n",
      "Iteration 24 in epoch 1\r\n",
      "Iteration 25 in epoch 1\r\n",
      "Iteration 26 in epoch 1\r\n",
      "Iteration 27 in epoch 1\r\n",
      "Iteration 28 in epoch 1\r\n",
      "Iteration 29 in epoch 1\r\n",
      "Iteration 30 in epoch 1\r\n",
      "Iteration 31 in epoch 1\r\n",
      "Iteration 32 in epoch 1\r\n",
      "Iteration 33 in epoch 1\r\n",
      "Iteration 34 in epoch 1\r\n",
      "Iteration 35 in epoch 1\r\n",
      "Iteration 36 in epoch 1\r\n",
      "Iteration 37 in epoch 1\r\n",
      "Iteration 38 in epoch 1\r\n",
      "Iteration 39 in epoch 1\r\n",
      "Iteration 40 in epoch 1\r\n",
      "Iteration 41 in epoch 1\r\n",
      "Iteration 42 in epoch 1\r\n",
      "Iteration 43 in epoch 1\r\n",
      "Iteration 44 in epoch 1\r\n",
      "Iteration 45 in epoch 1\r\n",
      "Iteration 46 in epoch 1\r\n",
      "Iteration 47 in epoch 1\r\n",
      "Iteration 48 in epoch 1\r\n",
      "Iteration 49 in epoch 1\r\n",
      "Iteration 50 in epoch 1\r\n",
      "Iteration 51 in epoch 1\r\n",
      "Iteration 52 in epoch 1\r\n",
      "Iteration 53 in epoch 1\r\n",
      "Iteration 54 in epoch 1\r\n",
      "Iteration 55 in epoch 1\r\n",
      "Iteration 56 in epoch 1\r\n",
      "Iteration 57 in epoch 1\r\n",
      "Iteration 58 in epoch 1\r\n",
      "Iteration 59 in epoch 1\r\n",
      "Iteration 60 in epoch 1\r\n",
      "Iteration 61 in epoch 1\r\n",
      "Iteration 62 in epoch 1\r\n",
      "Iteration 63 in epoch 1\r\n",
      "Iteration 64 in epoch 1\r\n",
      "Iteration 65 in epoch 1\r\n",
      "Iteration 66 in epoch 1\r\n",
      "Iteration 67 in epoch 1\r\n",
      "Iteration 68 in epoch 1\r\n",
      "Iteration 69 in epoch 1\r\n",
      "Iteration 70 in epoch 1\r\n",
      "Iteration 71 in epoch 1\r\n",
      "Iteration 72 in epoch 1\r\n",
      "Iteration 73 in epoch 1\r\n",
      "Iteration 74 in epoch 1\r\n",
      "Iteration 75 in epoch 1\r\n",
      "Iteration 76 in epoch 1\r\n",
      "Iteration 77 in epoch 1\r\n",
      "Iteration 78 in epoch 1\r\n",
      "Iteration 79 in epoch 1\r\n",
      "Iteration 80 in epoch 1\r\n",
      "Epoch 2 completed in 234.65226888656616 seconds\r\n",
      "{'EPOCH': 1, 'TIME': 234.65226888656616, 'LOSSES': {'G': tensor(3.3250, device='cuda:0', grad_fn=<SubBackward0>), 'D': tensor(0.0514, device='cuda:0', grad_fn=<AddBackward0>), 'Dfake': tensor(0.0514, device='cuda:0', grad_fn=<DivBackward0>), 'Dreal': tensor(0., device='cuda:0', grad_fn=<DivBackward0>), 'OCR_fake': tensor(0.3302, device='cuda:0', grad_fn=<MulBackward0>), 'OCR_real': tensor(4.5323, device='cuda:0', grad_fn=<MeanBackward0>), 'w_fake': tensor(2.0413, device='cuda:0', grad_fn=<MulBackward0>), 'w_real': tensor(4.8077, device='cuda:0', grad_fn=<MeanBackward0>), 'cycle1': 0, 'cycle2': 0, 'lda1': 0, 'lda2': 0, 'KLD': 0}}\r\n",
      "Starting epoch 2/100000\r\n",
      "Iteration 1 in epoch 2\r\n",
      "Iteration 2 in epoch 2\r\n",
      "Iteration 3 in epoch 2\r\n",
      "Iteration 4 in epoch 2\r\n",
      "Iteration 5 in epoch 2\r\n",
      "Iteration 6 in epoch 2\r\n",
      "Iteration 7 in epoch 2\r\n",
      "Iteration 8 in epoch 2\r\n",
      "Iteration 9 in epoch 2\r\n",
      "Iteration 10 in epoch 2\r\n",
      "Iteration 11 in epoch 2\r\n",
      "Iteration 12 in epoch 2\r\n",
      "Iteration 13 in epoch 2\r\n",
      "Iteration 14 in epoch 2\r\n",
      "Iteration 15 in epoch 2\r\n",
      "Iteration 16 in epoch 2\r\n",
      "Iteration 17 in epoch 2\r\n",
      "Iteration 18 in epoch 2\r\n",
      "Iteration 19 in epoch 2\r\n",
      "Iteration 20 in epoch 2\r\n",
      "Iteration 21 in epoch 2\r\n",
      "Iteration 22 in epoch 2\r\n",
      "Iteration 23 in epoch 2\r\n",
      "Iteration 24 in epoch 2\r\n",
      "Iteration 25 in epoch 2\r\n",
      "Iteration 26 in epoch 2\r\n",
      "Iteration 27 in epoch 2\r\n",
      "Iteration 28 in epoch 2\r\n",
      "Iteration 29 in epoch 2\r\n",
      "Iteration 30 in epoch 2\r\n",
      "Iteration 31 in epoch 2\r\n",
      "Iteration 32 in epoch 2\r\n",
      "Iteration 33 in epoch 2\r\n",
      "Iteration 34 in epoch 2\r\n",
      "Iteration 35 in epoch 2\r\n",
      "Iteration 36 in epoch 2\r\n",
      "Iteration 37 in epoch 2\r\n",
      "Iteration 38 in epoch 2\r\n",
      "Iteration 39 in epoch 2\r\n",
      "Iteration 40 in epoch 2\r\n",
      "Iteration 41 in epoch 2\r\n",
      "Iteration 42 in epoch 2\r\n",
      "Iteration 43 in epoch 2\r\n",
      "Iteration 44 in epoch 2\r\n",
      "Iteration 45 in epoch 2\r\n",
      "Iteration 46 in epoch 2\r\n",
      "Iteration 47 in epoch 2\r\n",
      "Iteration 48 in epoch 2\r\n",
      "Iteration 49 in epoch 2\r\n",
      "Iteration 50 in epoch 2\r\n",
      "Iteration 51 in epoch 2\r\n",
      "Iteration 52 in epoch 2\r\n",
      "Iteration 53 in epoch 2\r\n",
      "Iteration 54 in epoch 2\r\n",
      "Iteration 55 in epoch 2\r\n",
      "Iteration 56 in epoch 2\r\n",
      "Iteration 57 in epoch 2\r\n",
      "Iteration 58 in epoch 2\r\n",
      "Iteration 59 in epoch 2\r\n",
      "Iteration 60 in epoch 2\r\n",
      "Iteration 61 in epoch 2\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/input/handwriting-v3/Handwriting-Transformers/train.py\", line 156, in <module>\r\n",
      "    main()\r\n",
      "  File \"/kaggle/input/handwriting-v3/Handwriting-Transformers/train.py\", line 95, in main\r\n",
      "    model.optimize_G_only()\r\n",
      "  File \"/kaggle/input/handwriting-v3/Handwriting-Transformers/models/model.py\", line 1030, in optimize_G_only\r\n",
      "    self.forward()\r\n",
      "  File \"/kaggle/input/handwriting-v3/Handwriting-Transformers/models/model.py\", line 617, in forward\r\n",
      "    self.text_encode, self.len_text = self.netconverter.encode(self.label)\r\n",
      "  File \"/kaggle/input/handwriting-v3/Handwriting-Transformers/models/OCR_network.py\", line 261, in encode\r\n",
      "    index = self.dict[char]\r\n",
      "KeyError: '@'\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ‚ñÅ‚ñà\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        loss-D ‚ñÅ‚ñà\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    loss-Dfake ‚ñÅ‚ñà\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    loss-Dreal ‚ñÅ‚ñÅ\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        loss-G ‚ñÅ‚ñà\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss-OCR_fake ‚ñÅ‚ñà\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss-OCR_real ‚ñÅ‚ñà\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   loss-w_fake ‚ñà‚ñÅ\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   loss-w_real ‚ñÅ‚ñà\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  timeperepoch ‚ñÅ‚ñà\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 1\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        loss-D 0.05135\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    loss-Dfake 0.05135\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    loss-Dreal 0.0\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        loss-G 3.32503\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss-OCR_fake 0.33024\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss-OCR_real 4.53234\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   loss-w_fake 2.04127\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   loss-w_real 4.80765\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  timeperepoch 234.65227\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mCOMBINED_DATA_TRAINING\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/adarshghimire10/hwt-final/runs/4hdlo8ig\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/adarshghimire10/hwt-final\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 4 media file(s), 0 artifact file(s) and 0 other file(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m/tmp/wandb/run-20240731_091523-4hdlo8ig/logs\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMyn2SUl55yTt0b4o10xA5A",
   "gpuType": "T4",
   "name": "",
   "version": ""
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5414776,
     "sourceId": 8990213,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5469670,
     "sourceId": 9068468,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5469803,
     "sourceId": 9068654,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5469976,
     "sourceId": 9068878,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5470017,
     "sourceId": 9068926,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5470110,
     "sourceId": 9069039,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 898.54092,
   "end_time": "2024-07-31T09:29:37.425044",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-31T09:14:38.884124",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
